{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(print \"multiplyProbImages aborting - zero overlap. Offset and matrices:\")? (eyeDetect.py, line 345)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Amit\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2862\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-9-27ee1aeb8595>\"\u001b[0m, line \u001b[0;32m3\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import ClassyVirtualReferencePoint as ClassyVirtualReferencePoint\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Amit\\Desktop\\vision\\optimeyes-master\\ClassyVirtualReferencePoint.py\"\u001b[1;36m, line \u001b[1;32m14\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from eyeDetect import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Amit\\Desktop\\vision\\optimeyes-master\\eyeDetect.py\"\u001b[1;36m, line \u001b[1;32m345\u001b[0m\n\u001b[1;33m    print \"multiplyProbImages aborting - zero overlap. Offset and matrices:\"\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(print \"multiplyProbImages aborting - zero overlap. Offset and matrices:\")?\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ClassyVirtualReferencePoint as ClassyVirtualReferencePoint\n",
    "import ransac\n",
    "\n",
    "# set doTraining = False to display debug graphics:\n",
    "# You should do this first. There should be a green line from your\n",
    "# forehead to one pupil; the end of the line is the estimate of pupil position. The blue\n",
    "# circles should generally track your pupils, though less reliably than the green line.\n",
    "# If performance is bad, you can tweak the \"TUNABLE PARAMETER\" lines. (This is a big\n",
    "# area where improvement is needed; probably some learning of parameters.)\n",
    "# Set True to run the main program:\n",
    "# You click where you're looking, and, after around 10-20 such clicks,\n",
    "# the program will learn the correspondence and start drawing a blue blur\n",
    "# where you look. It's important to keep your head still (in position AND angle)\n",
    "# or it won't work.\n",
    "doTraining = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def featureCenter(f):\n",
    "    return (.5*(f.mExtents[0]+f.mExtents[1]),.5*(f.mExtents[2]+f.mExtents[3]) )\n",
    "\n",
    "# returns center in form (y,x)\n",
    "def featureCenterXY(rect):\n",
    "    #eyes are arrays of the form [minX, minY, maxX, maxY]\n",
    "    return (.5*(rect[0]+rect[2]), .5*(rect[1]+rect[3]))\n",
    "\n",
    "def centeredBox(feature1, feature2, boxWidth, boxHeight, yOffsetToAdd = 0):\n",
    "    f1 = np.array(featureCenterXY(feature1))\n",
    "    f2 = np.array(featureCenterXY(feature2))\n",
    "    center = (f1[:]+f2[:])/2\n",
    "    center[1] += yOffsetToAdd\n",
    "    offset = np.array([boxWidth/2,boxHeight/2])\n",
    "    return np.concatenate( (center-offset, center+offset) )\n",
    "\n",
    "\n",
    "def contains(outerFeature, innerFeature):\n",
    "    p = featureCenterXY(innerFeature)\n",
    "    #eyes are arrays of the form [minX, minY, maxX, maxY]\n",
    "    return p[0] > outerFeature[0] and p[0] < outerFeature[2] and p[1] > outerFeature[1] and p[1] < outerFeature[3]\n",
    "\n",
    "def containsPoint(outerFeature, p):\n",
    "    #eyes are arrays of the form [minX, minY, maxX, maxY]\n",
    "    return p[0] > outerFeature[0] and p[0] < outerFeature[2] and p[1] > outerFeature[1] and p[1] < outerFeature[3]\n",
    "\n",
    "# Takes an ndarray of face rects, and an ndarray of eye rects.\n",
    "# Returns the first eyes that are inside the face but not inside each other.\n",
    "# Eyes are returned as the tuple (leftEye, rightEye)\n",
    "def getLeftAndRightEyes(faces, eyes):\n",
    "    #loop through detected faces. We'll do our processing on the first valid one.\n",
    "    if len(eyes)==0:\n",
    "        return ()\n",
    "    for face in faces:\n",
    "        for i in range(eyes.shape[0]):\n",
    "            for j in range(i+1,eyes.shape[0]):\n",
    "                leftEye = eyes[i] #by left I mean camera left\n",
    "                rightEye = eyes[j]\n",
    "                #eyes are arrays of the form [minX, minY, maxX, maxY]\n",
    "                if (leftEye[0]+leftEye[2]) > (rightEye[0]+rightEye[2]): #leftCenter is > rightCenter\n",
    "                    rightEye, leftEye = leftEye, rightEye #swap\n",
    "                if contains(leftEye,rightEye) or contains(rightEye, leftEye):#they overlap. One eye containing another is due to a double detection; ignore it\n",
    "                    debugPrint('rejecting double eye')\n",
    "                    continue\n",
    "                if leftEye[3] < rightEye[1] or rightEye[3] < leftEye[1]:#top of one is below (>) bottom of the other. One is likely a mouth or something, not an eye.\n",
    "                    debugPrint('rejecting non-level eyes')\n",
    "                    continue\n",
    "##                if leftEye.minY()>face.coordinates()[1] or rightEye.minY()>face.coordinates()[1]: #top of eyes in top 1/2 of face\n",
    "##                    continue;\n",
    "                if not (contains(face,leftEye) and contains(face,rightEye)):#face contains the eyes. This is our standard of humanity, so capture the face.\n",
    "                    debugPrint(\"face doesn't contain both eyes\")\n",
    "                    continue\n",
    "                return (leftEye, rightEye)\n",
    "\n",
    "    return ()\n",
    "\n",
    "verbose=True\n",
    "\n",
    "def debugPrint(s):\n",
    "    if verbose:\n",
    "        print(s)\n",
    "\n",
    "showMainImg=True;\n",
    "\n",
    "def debugImg(arr):\n",
    "    global showMainImg\n",
    "    showMainImg=False;\n",
    "    toShow = cv2.resize((arr-arr.min())*(1.0/(arr.max()-arr.min())),(0,0), fx=8,fy=8,interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imshow(WINDOW_NAME,toShow)\n",
    "\n",
    "# displays data that is stored in a sparse format. Uses the coords to draw the corresponding\n",
    "# element of the vector, on a blank image of dimensions shapeToCopy\n",
    "def debugImgOfVectors(vectorToShow, gradXcoords, gradYcoords, shapeToCopy):\n",
    "    img = np.zeros(shapeToCopy)\n",
    "    for i,gradXcoord in enumerate(gradXcoords):\n",
    "        img[gradYcoords[i]][gradXcoord] = vectorToShow[i]\n",
    "    debugImg(img)\n",
    "\n",
    "BLOWUP_FACTOR = 1 # Resizes image before doing the algorithm. Changing to 2 makes things really slow. So nevermind on this.\n",
    "RELEVANT_DIST_FOR_CORNER_GRADIENTS = 8*BLOWUP_FACTOR\n",
    "dilationWidth = 1+2*BLOWUP_FACTOR #must be an odd number\n",
    "dilationHeight = 1+2*BLOWUP_FACTOR #must be an odd number\n",
    "dilationKernel = np.ones((dilationHeight,dilationWidth),'uint8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writeEyeDebugImages = False #enable to export image files showing pupil center probability\n",
    "eyeCounter = 0\n",
    "\n",
    "# Returns (cy,cx) of the pupil center, where y is down and x is right. You should pass in a grayscale Cv2 image which\n",
    "# is closely cropped around the center of the eye (using the Haar cascade eye detector)\n",
    "def getPupilCenter(gray, getRawProbabilityImage=False):\n",
    "##    (scleraY, scleraX) = np.unravel_index(gray.argmax(),gray.shape)\n",
    "##    scleraColor = colors[scleraY,scleraX,:]\n",
    "##    img[scleraX,scleraY] = (255,0,0)\n",
    "##    img.colorDistance(skinColor[:]).save(disp)\n",
    "##    img.edges().save(disp)\n",
    "##    print skinColor, scleraColor\n",
    "    gray = gray.astype('float32')\n",
    "    if BLOWUP_FACTOR != 1:\n",
    "        gray = cv2.resize(gray, (0,0), fx=BLOWUP_FACTOR, fy=BLOWUP_FACTOR, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    IRIS_RADIUS = gray.shape[0]*.75/2 #conservative-large estimate of iris radius TODO: make this a tracked parameter--pass a prior-probability of radius based on last few iris detections. TUNABLE PARAMETER\n",
    "    #debugImg(gray)\n",
    "    dxn = cv2.Sobel(gray,cv2.CV_32F,1,0,ksize=3) #optimization opportunity: blur the image once, then just subtract 2 pixels in x and 2 in y. Should be equivalent.\n",
    "    dyn = cv2.Sobel(gray,cv2.CV_32F,0,1,ksize=3)\n",
    "    magnitudeSquared = np.square(dxn)+np.square(dyn)\n",
    "\n",
    "    # ########### Pupil finding\n",
    "    magThreshold = magnitudeSquared.mean()*.6 #only retain high-magnitude gradients. <-- VITAL TUNABLE PARAMETER\n",
    "                    # The value of this threshold is critical for good performance.\n",
    "                    # todo: adjust this threshold using more images. Maybe should train our tuned parameters.\n",
    "    # form a bool array, unrolled columnwise, which can index into the image.\n",
    "    # we will only use gradients whose magnitude is above the threshold, and\n",
    "    # (optionally) where the gradient direction meets characteristics such as being more horizontal than vertical.\n",
    "    gradsTouse = (magnitudeSquared>magThreshold) & (np.abs(4*dxn)>np.abs(dyn))\n",
    "    lengths = np.sqrt(magnitudeSquared[gradsTouse]) #this converts us to double format\n",
    "    gradDX = np.divide(dxn[gradsTouse],lengths) #unrolled columnwise\n",
    "    gradDY = np.divide(dyn[gradsTouse],lengths)\n",
    "##    debugImg(gradsTouse*255)\n",
    "##    ksize = 7 #kernel size = x width and y height of the filter\n",
    "##    sigma = 4\n",
    "##    blurredGray = cv2.GaussianBlur(gray, (ksize,ksize), sigma, borderType=cv2.BORDER_REPLICATE)\n",
    "##    debugImg(gray)\n",
    "##    blurredGray = cv2.blur(gray, (ksize,ksize)) #x width and y height. TODO: try alternately growing and eroding black instead of blurring?\n",
    "    #isDark = blurredGray < blurredGray.mean()\n",
    "    isDark = gray< (gray.mean()*.8)  #<-- TUNABLE PARAMETER\n",
    "    global dilationKernel\n",
    "    isDark = cv2.dilate(isDark.astype('uint8'), dilationKernel) #dilate so reflection goes dark too\n",
    "##    isDark = cv2.erode(isDark.astype('uint8'), dilationKernel)\n",
    "##    debugImg(isDark*255)\n",
    "    gradXcoords =np.tile( np.arange(dxn.shape[1]), [dxn.shape[0], 1])[gradsTouse] # build arrays holding the original x,y position of each gradient in the list.\n",
    "    gradYcoords =np.tile( np.arange(dxn.shape[0]), [dxn.shape[1], 1]).T[gradsTouse] # These lines are probably an optimization target for later.\n",
    "    minXForPupil = 0 #int(dxn.shape[1]*.3)\n",
    "##    #original method\n",
    "##    centers = np.array([[phi(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords) if isDark[cy][cx] else 0 for cx in range(dxn.shape[1])] for cy in range(dxn.shape[0])])\n",
    "    #histogram method\n",
    "    centers = np.array([[phiWithHist(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords, IRIS_RADIUS) if isDark[cy][cx] else 0 for cx in xrange(minXForPupil,dxn.shape[1])] for cy in xrange(dxn.shape[0])]).astype('float32')\n",
    "    # display outputs for debugging\n",
    "##    centers = np.array([[phiTest(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords) for cx in range(dxn.shape[1])] for cy in range(dxn.shape[0])])\n",
    "##    debugImg(centers)\n",
    "    maxInd = centers.argmax()\n",
    "    (pupilCy,pupilCx) = np.unravel_index(maxInd, centers.shape)\n",
    "    pupilCx += minXForPupil\n",
    "    pupilCy /= BLOWUP_FACTOR\n",
    "    pupilCx /= BLOWUP_FACTOR\n",
    "    if writeEyeDebugImages:\n",
    "        global eyeCounter\n",
    "        eyeCounter = (eyeCounter+1)%5 #write debug image every 5th frame\n",
    "        if eyeCounter == 1:\n",
    "            cv2.imwrite( \"eyeGray.png\", gray/gray.max()*255) #write probability images for our report\n",
    "            cv2.imwrite( \"eyeIsDark.png\", isDark*255)\n",
    "            cv2.imwrite( \"eyeCenters.png\", centers/centers.max()*255)\n",
    "    if getRawProbabilityImage:\n",
    "        return (pupilCy, pupilCx, centers)\n",
    "    else:\n",
    "        return (pupilCy, pupilCx)\n",
    "\n",
    "\n",
    "lastCornerProb = np.ones([1,1])\n",
    "\n",
    "#This was a failed attempt to find eye corners, not used in final version.\n",
    "# Returns (cy,cx) of the eye corner, where y is down and x is right. You should pass in a grayscale Cv2 image which\n",
    "# is closely cropped around the corner of the eye (using the Haar cascade eye detector)\n",
    "def getEyeCorner(gray):\n",
    "##    (scleraY, scleraX) = np.unravel_index(gray.argmax(),gray.shape)\n",
    "##    scleraColor = colors[scleraY,scleraX,:]\n",
    "##    img[scleraX,scleraY] = (255,0,0)\n",
    "##    img.colorDistance(skinColor[:]).save(disp)\n",
    "##    img.edges().save(disp)\n",
    "##    print skinColor, scleraColor\n",
    "\n",
    "    if BLOWUP_FACTOR != 1:\n",
    "        gray = cv2.resize(gray, (0,0), fx=BLOWUP_FACTOR, fy=BLOWUP_FACTOR, interpolation=cv2.INTER_LINEAR)\n",
    "    gray = gray.astype('float32')\n",
    "    #debugImg(gray)\n",
    "    dxn = cv2.Sobel(gray,cv2.CV_32F,1,0,ksize=3) #optimization opportunity: blur the image once, then just subtract 2 pixels in x and 2 in y. Should be equivalent.\n",
    "    dyn = cv2.Sobel(gray,cv2.CV_32F,0,1,ksize=3)\n",
    "    magnitudeSquared = np.square(dxn)+np.square(dyn)\n",
    "##    debugImg(np.sqrt(magnitudeSquared))\n",
    "    # ########### Eye corner finding. TODO: limit gradients to search area\n",
    "    rangeOfXForCorner = int(dxn.shape[1]/2)\n",
    "    magThreshold = magnitudeSquared.mean()*.5 #only retain high-magnitude gradients. todo: adjust this threshold using more images. Maybe should train our tuned parameters.\n",
    "    # form a bool array, unrolled columnwise, which can index into the image.\n",
    "    # we will only use gradients whose magnitude is above the threshold, and\n",
    "    # (optionally) where the gradient direction meets characteristics such as being more horizontal than vertical.\n",
    "    gradsTouse = (magnitudeSquared>magThreshold) & (np.abs(2*dyn)>np.abs(dxn))\n",
    "    lengths = np.sqrt(magnitudeSquared[gradsTouse])\n",
    "    gradDX = np.divide(dxn[gradsTouse],lengths) #unrolled columnwise\n",
    "    gradDY = np.divide(dyn[gradsTouse],lengths)\n",
    "    gradXcoords =np.tile( np.arange(dxn.shape[1]), [dxn.shape[0], 1])[gradsTouse] # build arrays holding the original x,y position of each gradient in the list.\n",
    "    gradYcoords =np.tile( np.arange(dxn.shape[0]), [dxn.shape[1], 1]).T[gradsTouse] # These lines are probably an optimization target for later.\n",
    "##    debugImgOfVectors(gradDY,gradXcoords,gradYcoords, dxn.shape)\n",
    "    centers = np.array([[phiCorner(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords) for cx in range(rangeOfXForCorner)] for cy in range(dxn.shape[0])])\n",
    "##    debugImg(centers)\n",
    "    # Tracking -- use prior beliefs about corner position\n",
    "    global lastCornerProb\n",
    "    weightOnNew = 1\n",
    "    prior = np.ones(centers.shape)*(lastCornerProb.mean()*.5)*(1-weightOnNew) # fill with default value\n",
    "    startPrior = [0,0]\n",
    "    endPrior = [0,0]\n",
    "    startNew = [0,0]\n",
    "    endNew = [0,0]\n",
    "    for i in xrange(2):\n",
    "        diff = lastCornerProb.shape[i]-centers.shape[i]\n",
    "        if diff >= 0: # new is smaller\n",
    "            startPrior[i] = int(diff/2)\n",
    "            endPrior[i] = startPrior[i]+centers.shape[i]\n",
    "            startNew[i]=0\n",
    "            endNew[i]=centers.shape[i]\n",
    "        else: # prior is smaller\n",
    "            startPrior[i] = 0\n",
    "            endPrior[i] = lastCornerProb.shape[i]\n",
    "            startNew[i]=int(-diff/2)\n",
    "            endNew[i]=startNew[i]+lastCornerProb.shape[i]\n",
    "    prior[startNew[0]:endNew[0]][startNew[1]:endNew[1]] = (1-weightOnNew)*lastCornerProb[startPrior[0]:endPrior[0]][startPrior[1]:endPrior[1]]\n",
    "    centers = centers * (1/centers.max())\n",
    "    centers = centers * (weightOnNew + prior)\n",
    "##    debugImg(centers)\n",
    "    (cornerCy,cornerCx) = np.unravel_index(centers.argmax(), centers.shape)\n",
    "    cornerCy /= BLOWUP_FACTOR\n",
    "    cornerCx /= BLOWUP_FACTOR\n",
    "    return (cornerCy, cornerCx)\n",
    "\n",
    "# Estimates the probability that the given cx,cy is the pupil center, by taking\n",
    "# (its vector to each gradient location) dot (the gradient vector)\n",
    "def phi(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords, IRIS_RADIUS):\n",
    "    vecx = gradXcoords-cx\n",
    "    vecy = gradYcoords-cy\n",
    "    lengthsSquared = np.square(vecx)+np.square(vecy)\n",
    "    valid = (lengthsSquared > 0) & (lengthsSquared < IRIS_RADIUS**2) #avoid divide by zero, only use nearby gradients.\n",
    "    dotProd = np.multiply(vecx,gradDX)+np.multiply(vecy,gradDY)\n",
    "    valid = valid & (dotProd > 0) # only use vectors in the same direction (i.e. the dark-to-light transition direction is away from us. The good gradients look like that.)\n",
    "    dotProd = np.square(dotProd[valid]) # dot products squared\n",
    "    dotProd = np.divide(dotProd,lengthsSquared[valid]) #normalized squared dot products. Should range from 0 to 1.\n",
    "##    import pdb;pdb.set_trace()\n",
    "    dotProd = dotProd[dotProd > .9] #only count dot products that are really close\n",
    "    return np.sum(dotProd) # this is equivalent to normalizing vecx and vecy, because it takes dotProduct^2 / length^2\n",
    "\n",
    "# Estimates the probability that the given cx,cy is the pupil center, by taking\n",
    "# (its vector to each gradient location) dot (the gradient vector)\n",
    "# only uses gradients which are near the peak of a histogram of distance\n",
    "# cx and cy may be integers or floating point.\n",
    "def phiWithHist(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords, IRIS_RADIUS):\n",
    "    vecx = gradXcoords-cx\n",
    "    vecy = gradYcoords-cy\n",
    "    lengthsSquared = np.square(vecx)+np.square(vecy)\n",
    "    # bin the distances between 1 and IRIS_RADIUS. We'll discard all others.\n",
    "    binWidth = 1 #TODO: account for webcam resolution. Also, maybe have it transform ellipses to circles when on the sides? (hard)\n",
    "    numBins =  int(np.ceil((IRIS_RADIUS-1)/binWidth))\n",
    "    bins = [(1+binWidth*index)**2 for index in xrange(numBins+1)] #express bin edges in terms of length squared\n",
    "    hist = np.histogram(lengthsSquared, bins)[0]\n",
    "    maxBin = hist.argmax()\n",
    "    slop = binWidth\n",
    "    valid = (lengthsSquared > max(1,bins[maxBin]-slop)) &  (lengthsSquared < bins[maxBin+1]+slop) #use only points near the histogram distance\n",
    "    dotProd = np.multiply(vecx,gradDX)+np.multiply(vecy,gradDY)\n",
    "    valid = valid & (dotProd > 0) # only use vectors in the same direction (i.e. the dark-to-light transition direction is away from us. The good gradients look like that.)\n",
    "    dotProd = np.square(dotProd[valid]) # dot products squared\n",
    "    dotProd = np.divide(dotProd,lengthsSquared[valid]) #make normalized squared dot products\n",
    "##    dotProd = dotProd[dotProd > .9] #only count dot products that are really close\n",
    "    dotProd = np.square(dotProd) # squaring puts an even higher weight on values close to 1\n",
    "    return np.sum(dotProd) # this is equivalent to normalizing vecx and vecy, because it takes dotProduct^2 / length^2\n",
    "\n",
    "# Failed attempt to find probability that the given cx,cy is an eye corner, not\n",
    "# used in final version. Works by taking\n",
    "# (its vector to each gradient location) dot (the gradient vector). The corner\n",
    "# should have a near-zero dot product with its nearby vectors, because the\n",
    "# eyelids form lines that point right at the eye corner (so their gradients are\n",
    "# at a 90 degree angle to it).\n",
    "# only uses gradients which are near the peak of a histogram of distance\n",
    "# cx and cy may be integers or floating point.\n",
    "def phiCorner(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords):\n",
    "    vecx = gradXcoords-cx\n",
    "    vecy = gradYcoords-cy\n",
    "    angles = np.arctan2(vecy,vecx)\n",
    "    lengthsSquared = np.square(vecx)+np.square(vecy)\n",
    "    valid = (lengthsSquared > 0) & (lengthsSquared < RELEVANT_DIST_FOR_CORNER_GRADIENTS) & (vecx>0.4)#RIGHT EYE ASSUMPTION\n",
    "    numBins = 10\n",
    "##    binWidth = 2.0/numBins\n",
    "##    slop = binWidth/2\n",
    "##    bins = [binWidth*i for i in xrange(numBins+1)]\n",
    "##    hist = np.histogram(gradDY[valid], bins)[0]\n",
    "    (hist,bins) = np.histogram(angles, numBins, (-math.pi,math.pi))\n",
    "    slop = math.pi/numBins/2\n",
    "    maxBin = hist.argmax()\n",
    "    hist[maxBin] = 0;\n",
    "    hist[max(0,maxBin-1)]=0;\n",
    "    hist[min(maxBin+1,numBins-1)]=0;\n",
    "    secondMaxBin = hist.argmax();\n",
    "    stat = angles #gradDY\n",
    "    validBina = valid & ((bins[maxBin]-slop<stat)&(stat<bins[maxBin+1]+slop))\n",
    "    validBinb = valid & ((bins[secondMaxBin]-slop<stat)&(stat<bins[secondMaxBin+1]+slop))#use only points near the histogram max\n",
    "\n",
    "\n",
    "    dotProd = np.multiply(vecx,gradDX)+np.multiply(vecy,gradDY)\n",
    "    dotProda = np.square(dotProd[validBina]) # dot products squared\n",
    "    dotProdb = np.square(dotProd[validBinb]) # dot products squared\n",
    "    dotProda = 1.0-np.divide(dotProda,lengthsSquared[validBina]) #make normalized squared dot products, and take 1-them so 0 gets the highest score\n",
    "    dotProdb = 1.0-np.divide(dotProdb,lengthsSquared[validBinb]) #make normalized squared dot products, and take 1-them so 0 gets the highest score\n",
    "##    import pdb;pdb.set_trace()\n",
    "    dotProda = np.square(dotProda) #only count dot products that are really close\n",
    "    dotProdb = np.square(dotProdb) #only count dot products that are really close\n",
    "    suma = np.sum(dotProda) # this is equivalent to normalizing vecx and vecy, because it takes dotProduct^2 / length^2\n",
    "    sumb = np.sum(dotProdb) # this is equivalent to normalizing vecx and vecy, because it takes dotProduct^2 / length^2\n",
    "    return min(suma,sumb)+.5*max(suma,sumb) #this score should favor a strong bimodal histogram shape\n",
    "\n",
    "#for debugging\n",
    "def phiTest(cx,cy,gradDX,gradDY,gradXcoords,gradYcoords):\n",
    "    for ix,xcoord in enumerate(gradXcoords):\n",
    "        if xcoord==cx and gradYcoords[ix]==cy:\n",
    "            return np.atan2(gradDY[ix],gradDX[ix])\n",
    "    return 0\n",
    "\n",
    "# multiplies newProb and priorToMultiply\n",
    "# YXoffsetOfSecondWithinFirst - priorToMultiply will be shifted by this amount in space\n",
    "# defaultPriorValue - if not all of newProb is covered by priorToMultiply, this scalar goes in the uncovered areas.\n",
    "def multiplyProbImages(newProb, priorToMultiply, YXoffsetOfSecondWithinFirst, defaultPriorValue):\n",
    "    if np.any(YXoffsetOfSecondWithinFirst > newProb.shape) or np.any(-YXoffsetOfSecondWithinFirst > priorToMultiply.shape):\n",
    "        #print(\"multiplyProbImages aborting - zero overlap. Offset and matrices:\")\n",
    "        print(YXoffsetOfSecondWithinFirst)\n",
    "        print(newProb.shape)\n",
    "        print(priorToMultiply.shape)\n",
    "        return newProb*defaultPriorValue\n",
    "    prior = np.ones(newProb.shape)*defaultPriorValue # Most of this will get overwritten. For areas that won't be, with fill with default value.\n",
    "    #offsets\n",
    "    startPrior = [0,0]\n",
    "    endPrior = [0,0]\n",
    "    startNew = [0,0]\n",
    "    endNew = [0,0]\n",
    "    for i in xrange(2):\n",
    "        #offset=0\n",
    "        # NOT THIS: x[1:2][1:2]\n",
    "        # THIS: x[1:2,1:2]\n",
    "        offset = int(round(YXoffsetOfSecondWithinFirst[i])) # how much to offset 'prior' within 'newProb', for the current dimension\n",
    "        print (offset)\n",
    "        if offset >= 0: # prior goes right of 'newProb', in the world. So prior will be copied into newProb at a positive offset\n",
    "            startPrior[i] = 0 #index within prior\n",
    "            endPrior[i] = min(priorToMultiply.shape[i],newProb.shape[i]-offset) #how much of prior to copy\n",
    "            startNew[i]=offset\n",
    "            endNew[i]=offset+endPrior[i]\n",
    "        else: # prior goes left of 'newProb', in the world.\n",
    "            startPrior[i] = -offset\n",
    "            endPrior[i] = min(priorToMultiply.shape[i], startPrior[i]+newProb.shape[i])\n",
    "            startNew[i]=0\n",
    "            endNew[i]=endPrior[i]-startPrior[i]\n",
    "    prior[startNew[0]:endNew[0],startNew[1]:endNew[1]] = priorToMultiply[startPrior[0]:endPrior[0],startPrior[1]:endPrior[1]]\n",
    "    #prior[1:10,1:10] = priorToMultiply[1:10,1:10]\n",
    "    #now, prior holds the portion of priorToMultiply which overlapped newProb.\n",
    "    return newProb * prior\n",
    "\n",
    "\n",
    "## img: cv2 image in uint8 format\n",
    "## cascade: object you made with cv2.CascadeClassifier(\"./haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "## minimumFeatureSize (ySize,xSize) tuple holding the smallest object you'd be looking for. E.g. (30,30)\n",
    "## returns a numpy ndarray where rects[0] is the first detection, and holds [minX, minY, maxX, maxY] where +Y = downward\n",
    "def detect(img, cascade, minimumFeatureSize=(20,20)):\n",
    "    if cascade.empty():\n",
    "        raise(Exception(\"There was a problem loading your Haar Cascade xml file.\"))\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=1, minSize=minimumFeatureSize)\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "    rects[:,2:] += rects[:,:2] #convert last coord from (width,height) to (maxX, maxY)\n",
    "    return rects\n",
    "\n",
    "def draw_rects(img, rects, color):\n",
    "    for x1, y1, x2, y2 in rects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# init the filters we'll use below\n",
    "haarFaceCascade = cv2.CascadeClassifier(\"./haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "haarEyeCascade = cv2.CascadeClassifier(\"./haarcascades/haarcascade_eye.xml\")\n",
    "#img.listHaarFeatures() displays these Haar options:\n",
    "#['eye.xml', 'face.xml', 'face2.xml', 'face3.xml', 'face4.xml', 'fullbody.xml', 'glasses.xml', 'lefteye.xml', #'left_ear.xml', 'left_eye2.xml', 'lower_body.xml', 'mouth.xml', 'nose.xml', 'profile.xml',\n",
    "#'right_ear.xml', 'right_eye.xml', 'right_eye2.xml', 'two_eyes_big.xml', 'two_eyes_small.xml', 'upper_body.xml', #'upper_body2.xml']\n",
    "OffsetRunningAvg = None\n",
    "PupilSpacingRunningAvg = None\n",
    "\n",
    "# global stuff for Adam's virtual ref point\n",
    "#initialize the SURF descriptor\n",
    "hessianThreshold = 500\n",
    "nOctaves = 4\n",
    "nOctaveLayers = 2\n",
    "extended = True\n",
    "upright = True\n",
    "detector = cv2.xfeatures2d.SURF_create(hessianThreshold, nOctaves, nOctaveLayers, extended, upright)\n",
    "#figure out a way to nearest neighbor map to index\n",
    "virtualpoint = None\n",
    "warm=0\n",
    "\n",
    "#*********  getOffset  **********\n",
    "# INPUTS:\n",
    "# frame - a color numpy image.\n",
    "# allowDebugDisplay - pass True if you want it to draw pupil centers, etc on \"frame\" and then display it.\n",
    "# Display requires that you called this line to create the window: previewWindow = cv2.namedWindow(WINDOW_NAME)\n",
    "# trackAverageOffset - output will be a moving average rather than instantaneous value\n",
    "# directInferenceLeftRight - combines probability images from left and right to hopefully reduce noise in estimation of pupil offset\n",
    "# Returns a list of two tuples of pupil offsets from the forehead dot. Specifically:\n",
    "# [(cameraLeftEyeOffsetX, cameraLeftEyeOffsetY),  (cameraRightEyeOffsetX, cameraRightEyeOffsetY) ]\n",
    "# If no valid face is found, returns None.\n",
    "# Requires the functions above.\n",
    "def getOffset(frame, allowDebugDisplay=True, trackAverageOffset=True, directInferenceLeftRight=True):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    # find faces and eyes\n",
    "    minFaceSize = (80,80)\n",
    "    minEyeSize = (25,25)\n",
    "    faces = detect(gray,haarFaceCascade,minFaceSize)\n",
    "    eyes = detect(gray,haarEyeCascade,minEyeSize)\n",
    "    drawKeypoints = allowDebugDisplay #can set this false if you don't want the keypoint ID numbers\n",
    "    if allowDebugDisplay:\n",
    "        output = frame\n",
    "        draw_rects(output,faces,(0,255,0)) #BGR format\n",
    "    else:\n",
    "        output = None\n",
    "##        draw_rects(output,eyes,(255,0,0))\n",
    "    leftEye_rightEye = getLeftAndRightEyes( faces, eyes)\n",
    "    if leftEye_rightEye: #if we found valid eyes in a face\n",
    "##            draw_rects(output,leftEye_rightEye,(0,0,255)) #BGR format\n",
    "        xDistBetweenEyes = (leftEye_rightEye[0][0]+leftEye_rightEye[0][1]+leftEye_rightEye[1][0]+leftEye_rightEye[1][1])/4 #for debugging reference point\n",
    "        pupilXYList = []\n",
    "        pupilCenterEstimates = []\n",
    "        for eyeIndex, eye in enumerate(leftEye_rightEye):\n",
    "##        eye = leftEye_rightEye[1]\n",
    "            corner = eye.copy()\n",
    "\n",
    "            #eyes are arrays of the form [minX, minY, maxX, maxY]\n",
    "            eyeWidth = eye[2]-eye[0]\n",
    "            eyeHeight = eye[3]-eye[1]\n",
    "            eye[0] += eyeWidth*.20\n",
    "            eye[2] -= eyeWidth*.15\n",
    "            eye[1] += eyeHeight*.3\n",
    "            eye[3] -= eyeHeight*.2\n",
    "            eye = np.round(eye)\n",
    "            eyeImg = gray[eye[1]:eye[3], eye[0]:eye[2]]\n",
    "            if directInferenceLeftRight:\n",
    "                (cy,cx, centerProb) = getPupilCenter(eyeImg, True)\n",
    "                pupilCenterEstimates.append(centerProb.copy())\n",
    "            else:\n",
    "                (cy,cx) = getPupilCenter(eyeImg, True)\n",
    "            pupilXYList.append( (cx+eye[0],cy+eye[1])  )\n",
    "            if allowDebugDisplay:\n",
    "                cv2.rectangle(output, (eye[0], eye[1]), (eye[2], eye[3]), (0,255,0), 1)\n",
    "                cv2.circle(output, pupilXYList[eyeIndex], 3, (255,0,0),thickness=1) #BGR format\n",
    "\n",
    "\n",
    "        # tear-duct of the camera-right eye\n",
    "##        corner[0] += eyeWidth*0\n",
    "##        corner[2] -= eyeWidth*.6\n",
    "##        corner[1] += eyeHeight*.4\n",
    "##        corner[3] -= eyeHeight*.35\n",
    "##        corner = np.round(corner)\n",
    "##        cv2.rectangle(output, (corner[0], corner[1]), (corner[2], corner[3]), (0,0,0), 1)\n",
    "##        cornerImg = gray[corner[1]:corner[3], corner[0]:corner[2]]\n",
    "##        (cornerCy,cornerCx) = getEyeCorner(cornerImg)\n",
    "##        cv2.circle(output, (cornerCx+corner[0],cornerCy+corner[1]), 2, (255,255,0),thickness=1) #BGR format\n",
    "\n",
    "        # direct inference combination of the two eye probability images.\n",
    "        global PupilSpacingRunningAvg\n",
    "        if directInferenceLeftRight:\n",
    "            # these vectors are in XY format\n",
    "            pupilSpacing = np.array(pupilXYList[1])-np.array(pupilXYList[0]) # vector from pupil 0 to pupil 1\n",
    "            if PupilSpacingRunningAvg is None:\n",
    "                PupilSpacingRunningAvg = pupilSpacing\n",
    "            else:\n",
    "                weightOnNew = .03\n",
    "                PupilSpacingRunningAvg = (1-weightOnNew)*PupilSpacingRunningAvg + weightOnNew*pupilSpacing  # vector from pupil 0 to pupil 1\n",
    "            if allowDebugDisplay:\n",
    "                cv2.line(output, (int(pupilXYList[0][0]),int(pupilXYList[0][1])), (int(pupilXYList[0][0]+PupilSpacingRunningAvg[0]), int(pupilXYList[0][1]+PupilSpacingRunningAvg[1])), (0,100,100))\n",
    "            imageZeroToOneVector = leftEye_rightEye[1][0:2]-leftEye_rightEye[0][0:2] # vector from eyeImg 0 to 1\n",
    "            positionOfZeroWithinOne = PupilSpacingRunningAvg-imageZeroToOneVector; # the extra distance that wasn't covered by the bounding boxes should be applied as an offset when multiplying images.\n",
    "            ksize = 5 #kernel size = x width and y height of the filter\n",
    "            sigma = 2\n",
    "            for i,centerEstimate in enumerate(pupilCenterEstimates):\n",
    "                pupilCenterEstimates[i] = cv2.GaussianBlur(pupilCenterEstimates[i], (ksize,ksize), sigma, borderType=cv2.BORDER_REPLICATE)\n",
    "            jointPupilProb = multiplyProbImages(pupilCenterEstimates[1], pupilCenterEstimates[0], positionOfZeroWithinOne[::-1], 0) # the [::-1] reverse the order, so it's YX instead of the XY that these vectors are in\n",
    "##            debugImg(jointPupilProb)\n",
    "            maxInd = jointPupilProb.argmax()\n",
    "##            cv2.imwrite( \"eye0.png\", pupilCenterEstimates[0]/pupilCenterEstimates[0].max()*255) #write probability images for our report\n",
    "##            cv2.imwrite( \"eye1.png\", pupilCenterEstimates[1]/pupilCenterEstimates[1].max()*255)\n",
    "##            cv2.imwrite( \"eyeJoint.png\", jointPupilProb/jointPupilProb.max()*255)\n",
    "            (pupilCy,pupilCx) = np.unravel_index(maxInd, jointPupilProb.shape) # coordinates in the eye 1 (camera-right eye) image\n",
    "            pupilXYList[0]=pupilXYList[1]=(pupilCx + leftEye_rightEye[1][0],pupilCy + leftEye_rightEye[1][1]) #convert to absolute image coordinates\n",
    "\n",
    "\n",
    "        useSURFReference = True\n",
    "        if not useSURFReference: # this code assumes you have drawn a dark dot on your forehead. Should be drawn between the eyes, about the size of the iris.\n",
    "            dotSearchBox = np.round( centeredBox(leftEye_rightEye[0], leftEye_rightEye[1], xDistBetweenEyes*.2, xDistBetweenEyes*.3, -xDistBetweenEyes*.09 ) ).astype('int')\n",
    "\n",
    "            (refY,refX) = getPupilCenter(gray[dotSearchBox[1]:dotSearchBox[3], dotSearchBox[0]:dotSearchBox[2]])\n",
    "            refXY = (refX+dotSearchBox[0],refY+dotSearchBox[1])\n",
    "            if allowDebugDisplay:\n",
    "                cv2.rectangle(output, (dotSearchBox[0], dotSearchBox[1]), (dotSearchBox[2], dotSearchBox[3]), (128,0,128), 1)\n",
    "                cv2.circle(output, refXY, 2, (0,0,100),thickness=1) #BGR format\n",
    "        else: # Adam's virtual reference point code. See paper for how it works.\n",
    "            refXY = (0,0)\n",
    "            global warm, virtualpoint\n",
    "            warm += 1\n",
    "            if warm > 8:\n",
    "                #adam\n",
    "                face = faces[0]#expect the first one\n",
    "                faceImg = gray[face[1]:face[3], face[0]:face[2]]\n",
    "                cornerImg = gray[corner[1]:corner[3], corner[0]:corner[2]]\n",
    "                if virtualpoint == None: #we haven't set up the reference point yet\n",
    "                    haystackKeypoints, haystackDescriptors = detector.detectAndCompute(gray, mask=None)\n",
    "                    if len(haystackKeypoints) != 0:\n",
    "                        betweenEyes = (np.array(featureCenterXY(leftEye_rightEye[0]))+np.array(featureCenterXY(leftEye_rightEye[1])))/2\n",
    "                        virtualpoint = ClassyVirtualReferencePoint.ClassyVirtualReferencePoint(haystackKeypoints, haystackDescriptors, (betweenEyes[0], betweenEyes[1]), face, leftEye_rightEye[0], leftEye_rightEye[1])\n",
    "                    else:\n",
    "                        print (\"begin fail\")\n",
    "                else: #we've already created it\n",
    "                    keypoints, descriptors = detector.detectAndCompute(gray, mask=None)\n",
    "                    if drawKeypoints:\n",
    "                        imgToDrawOn = output\n",
    "                    else:\n",
    "                        imgToDrawOn = None\n",
    "                    if len(descriptors) != 0:\n",
    "                        refXY  = virtualpoint.getReferencePoint(keypoints, descriptors, face, leftEye_rightEye[0], leftEye_rightEye[1], imgToDrawOn)\n",
    "            # end of Adam's reference point code\n",
    "\n",
    "        for i in xrange(len(pupilXYList)):\n",
    "            pupilXYList[i] = ( pupilXYList[i][0]-refXY[0], pupilXYList[i][1]-refXY[1])\n",
    "        pupilXYList = list(pupilXYList[0])+ list(pupilXYList[1]) #concatenate cam-left and cam-right coordinate tuples to make a single length 4 vector [x,y,x,y]\n",
    "\n",
    "        if trackAverageOffset: # this frame's estimated offset will be a weighted average of the new measurement and the last frame's estimated offset\n",
    "            global OffsetRunningAvg\n",
    "            if OffsetRunningAvg is None:\n",
    "                OffsetRunningAvg = np.array( [0,0])\n",
    "            weightOnNew = .4; #Tuned parameter, must be >0 and <=1.0. Increase for faster response, decrease for better noise rejection.\n",
    "            currentOffset = (np.array(pupilXYList[:2])+np.array(pupilXYList[2:]))/2\n",
    "            OffsetRunningAvg = (1.0-weightOnNew)*OffsetRunningAvg + weightOnNew*currentOffset\n",
    "            pupilXYList = OffsetRunningAvg\n",
    "##            import pdb; pdb.set_trace()\n",
    "            if allowDebugDisplay:\n",
    "                cv2.line(output, (int(refXY[0]),int(refXY[1])), (int(refXY[0]+pupilXYList[0]), int(refXY[1]+pupilXYList[1])), (0,255,100))\n",
    "\n",
    "        if allowDebugDisplay and showMainImg:\n",
    "            # Double size\n",
    "            cv2.imshow(WINDOW_NAME, cv2.resize(output,(0,0), fx=2,fy=2,interpolation=cv2.INTER_NEAREST) )\n",
    "            # original size\n",
    "\n",
    "        return tuple(pupilXYList) # if trackAverageOffset, it's length 2 and holds the average offset. Else, it's length 4 (old code)\n",
    "\n",
    "    else: # no valid face was found\n",
    "        if allowDebugDisplay:\n",
    "            cv2.imshow(WINDOW_NAME, cv2.resize(output,(0,0), fx=2,fy=2,interpolation=cv2.INTER_NEAREST) )\n",
    "        return None\n",
    "\n",
    "\n",
    "class LinearLeastSquaresModel:\n",
    "    \"\"\"linear system solved using linear least squares\n",
    "\n",
    "    This class fulfills the model interface needed by the ransac() function.\n",
    "\n",
    "    \"\"\"\n",
    "    # lists of indices of input and output columns\n",
    "    def __init__(self,input_columns,output_columns,debug=False):\n",
    "        self.input_columns = input_columns\n",
    "        self.output_columns = output_columns\n",
    "        self.debug = debug\n",
    "    def fit(self, data):\n",
    "##        A = numpy.vstack([data[:,i] for i in self.input_columns]).T\n",
    "##        B = numpy.vstack([data[:,i] for i in self.output_columns]).T\n",
    "##        x,resids,rank,s = scipy.linalg.lstsq(A,B)\n",
    "##        return x\n",
    "        HT = np.linalg.lstsq(data[:,self.input_columns], data[:,self.output_columns])[0] # returns a tuple, where index 0 is the solution matrix.\n",
    "        return HT\n",
    "\n",
    "    def get_error( self, data, model):\n",
    "        B_fit = data[:,self.input_columns].dot(model)\n",
    "        err_per_point = np.sum((data[:,self.output_columns]-B_fit)**2,axis=1) # sum squared error per row\n",
    "        err_per_point = np.sqrt(err_per_point) # I'll see if this helps. If not remove for speed.\n",
    "        return err_per_point\n",
    "\n",
    "def getFeatures(XYOffsets, quadratic = True):\n",
    "##    print XYOffsets\n",
    "    if len(XYOffsets.shape)==1:\n",
    "        numRows=1\n",
    "        XYOffsets.shape = (numRows,XYOffsets.shape[0])\n",
    "    else:\n",
    "        numRows =XYOffsets.shape[0]\n",
    "    numCols = XYOffsets.shape[1]\n",
    "\n",
    "    data = np.concatenate( (XYOffsets, np.ones( (XYOffsets.shape[0],1)) ) , axis=1) # [x,y,1]\n",
    "    if quadratic:\n",
    "        squaredFeatures = np.square(XYOffsets)\n",
    "        squaredFeatures.shape = (numRows,numCols)\n",
    "        xy = XYOffsets[:,0]*XYOffsets[:,1]\n",
    "        xy.shape = (numRows,1)\n",
    "##        print(xy.shape)\n",
    "\n",
    "        data = np.concatenate( (data,squaredFeatures, xy ) , axis=1) # [x,y,1,x^2,y^2,xy]\n",
    "    return data\n",
    "\n",
    "\n",
    "RANSAC_MIN_INLIERS = 7\n",
    "def RANSACFitTransformation(OffsetsAndPixels):\n",
    "    numInputCols = OffsetsAndPixels.shape[1]-2\n",
    "    data = np.concatenate( (OffsetsAndPixels[:,0:numInputCols], OffsetsAndPixels[:,numInputCols:] ) , axis=1)\n",
    "\n",
    "    model = LinearLeastSquaresModel(range(numInputCols), (numInputCols,numInputCols+1))\n",
    "    minSeedSize = 5\n",
    "    iterations = 800\n",
    "    maxInlierError = 240 #**2\n",
    "    HT = ransac.ransac(data, model, minSeedSize, iterations, maxInlierError, RANSAC_MIN_INLIERS)\n",
    "    return HT\n",
    "\n",
    "def fitTransformation(OffsetsAndPixels):\n",
    "    offsets = np.concatenate( (OffsetsAndPixels[:,0:2], np.ones( (OffsetsAndPixels.shape[0],1)) ) , axis=1)\n",
    "    pixels = OffsetsAndPixels[:,2:]\n",
    "    HT = np.linalg.lstsq(offsets, pixels)[0] # returns a tuple, where index 0 is the solution matrix.\n",
    "    return HT\n",
    "\n",
    "WINDOW_NAME = \"preview\"\n",
    "def main():\n",
    "    cv2.namedWindow(WINDOW_NAME) # open a window to show debugging images\n",
    "    vc = cv2.VideoCapture(0) # Initialize the default camera\n",
    "    try:\n",
    "        if vc.isOpened(): # try to get the first frame\n",
    "            (readSuccessful, frame) = vc.read()\n",
    "        else:\n",
    "            raise(Exception(\"failed to open camera.\"))\n",
    "            readSuccessful = False\n",
    "    \n",
    "        while readSuccessful:\n",
    "            pupilOffsetXYList = getOffset(frame, allowDebugDisplay=True)\n",
    "            key = cv2.waitKey(10)\n",
    "            if key == 27: # exit on ESC\n",
    "                cv2.imwrite( \"lastOutput.png\", frame) #save the last-displayed image to file, for our report\n",
    "                break\n",
    "            # Get Image from camera\n",
    "            readSuccessful, frame = vc.read()\n",
    "    finally:\n",
    "        vc.release() #close the camera\n",
    "        cv2.destroyWindow(WINDOW_NAME) #close the window\n",
    "\n",
    "def mainForTraining():\n",
    "    import pygamestuff\n",
    "    crosshair = pygamestuff.Crosshair([7, 2], quadratic = False)\n",
    "    vc = cv2.VideoCapture(0) # Initialize the default camera\n",
    "    if vc.isOpened(): # try to get the first frame\n",
    "        (readSuccessful, frame) = vc.read()\n",
    "    else:\n",
    "        raise(Exception(\"failed to open camera.\"))\n",
    "        return\n",
    "\n",
    "    MAX_SAMPLES_TO_RECORD = 999999\n",
    "    recordedEvents=0\n",
    "    HT = None\n",
    "    try:\n",
    "        while readSuccessful and recordedEvents < MAX_SAMPLES_TO_RECORD and not crosshair.userWantsToQuit:\n",
    "            pupilOffsetXYList = getOffset(frame, allowDebugDisplay=False)\n",
    "            if pupilOffsetXYList is not None: #If we got eyes, check for a click. Else, wait until we do.\n",
    "                if crosshair.pollForClick():\n",
    "                    crosshair.clearEvents()\n",
    "                    #print( (xOffset,yOffset) )\n",
    "                    #do learning here, to relate xOffset and yOffset to screenX,screenY\n",
    "                    crosshair.record(pupilOffsetXYList)\n",
    "                    print (\"recorded something\")\n",
    "                    crosshair.remove()\n",
    "                    recordedEvents += 1\n",
    "                    if recordedEvents > RANSAC_MIN_INLIERS:\n",
    "    ##                    HT = fitTransformation(np.array(crosshair.result))\n",
    "                        resultXYpxpy =np.array(crosshair.result)\n",
    "                        features = getFeatures(resultXYpxpy[:,:-2])\n",
    "                        featuresAndLabels = np.concatenate( (features, resultXYpxpy[:,-2:] ) , axis=1)\n",
    "                        HT = RANSACFitTransformation(featuresAndLabels)\n",
    "                        print (HT)\n",
    "                if HT is not None: # draw predicted eye position\n",
    "                    currentFeatures =getFeatures( np.array( (pupilOffsetXYList[0], pupilOffsetXYList[1]) ))\n",
    "                    gazeCoords = currentFeatures.dot(HT)\n",
    "                    crosshair.drawCrossAt( (gazeCoords[0,0], gazeCoords[0,1]) )\n",
    "            readSuccessful, frame = vc.read()\n",
    "    \n",
    "        print (\"writing\")\n",
    "        crosshair.write() #writes data to a csv for MATLAB\n",
    "        crosshair.close()\n",
    "        print (\"HT:\\n\")\n",
    "        print (HT)\n",
    "        resultXYpxpy =np.array(crosshair.result)\n",
    "        print (\"eyeData:\\n\")\n",
    "        print (getFeatures(resultXYpxpy[:,:-2]))\n",
    "        print (\"resultXYpxpy:\\n\")\n",
    "        print (resultXYpxpy[:,-2:])\n",
    "    finally:\n",
    "        vc.release() #close the camera\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if doTraining:\n",
    "        mainForTraining()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
